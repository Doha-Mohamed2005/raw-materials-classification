# ğŸ­ Raw Materials Classification

## ğŸ“– Project Overview
This project implements a deep learning model for classifying raw materials (**wood, plastic, metal, glass**) based on image texture using **Convolutional Neural Networks (CNNs)** and **Transfer Learning**.  

- **Architectures:** ResNet18, EfficientNet-B1, MobileNetV3  
- **GUI:** Streamlit-based interface for image upload, predictions, confidence scores, and Grad-CAM visualizations  
- **Applications:** Industrial sorting and smart recycling systems

---

## âœ¨ Bonus Feature
**Texture Robustness under Varying Lighting, Shadow & Glare Conditions**  
> The model recognizes materials correctly even under different illumination, shadow, or glare conditions, simulating real factory settings.  

Achieved through **heavy augmentations** using Albumentations:  
`RandomBrightnessContrast`, `RandomShadow`, `GaussNoise`, `MotionBlur`

---

## ğŸ“‚ Dataset

- **Main Dataset:** Kaggle â€“ Material Dataset New (~15,000 images, focused on JPEGImages for classification)
-  **Link Dataset:** https://www.kaggle.com/datasets/alistairking/recyclable-and-household-waste-classification
- **Additional Custom Images:** Collected under extreme lighting, deep shadows, and strong glare (~15,000 images with augmentations)  
- **Total Images:** ~40,000  
- **Class Distribution:** Balanced across materials (visualized in `preprocessing/data_exploration.ipynb`)

---

## ğŸ§  Models Implemented
| Model           | Source        | Role                        |
|-----------------|---------------|----------------------------|
| **ResNet18**        | torchvision   | Baseline                   |
| **EfficientNet-B1** | timm          | Best accuracy              |
| **MobileNetV3**     | torchvision   | Lightweight & fast         |

**Training Details:** Pre-trained on ImageNet, fine-tuned with custom augmentations  
**Explainability:** Grad-CAM for model attention visualization  
**Bonus Features:** Heavy lighting augmentations, top-3 predictions with confidence scores

---

## ğŸ“Š Results
*(To be updated after final training)*

- **ResNet18:** xx% accuracy  
- **EfficientNet-B1:** xx% accuracy (Best performing)  
- **MobileNetV3:** xx% accuracy  

Confusion matrices, accuracy graphs, and performance under varying lighting are available in the `docs/` folder.

---

## ğŸ–¥ GUI Features
- Upload an image
- Display top-3 predicted classes with confidence scores
- Grad-CAM visualizations
- View accuracy/confusion matrix
- Compare results across models  

**Framework:** Streamlit

---

## âš™ï¸ Setup Instructions

```bash
# Clone repository
git clone https://github.com/Doha-Mohamed2005/raw-materials-classification.git
cd raw-materials-classification

# Install dependencies
pip install -r requirements.txt

# Run GUI
streamlit run gui/GuiApp.py
---
ğŸ—‚ Repository Structure
raw-materials-classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ custom_lighting_images/     # Custom images for robustness
â”‚   â””â”€â”€ README.md                   # Dataset description
â”œâ”€â”€ models/                         # Trained .pth files
â”œâ”€â”€ gui/                            # GuiApp.py
â”œâ”€â”€ src/                            # DataLoader.py, Train.py, Model_defs.py
â”œâ”€â”€ preprocessing/                  # Dataset preprocessing & augmentation
â”‚   â”œâ”€â”€ upload_dataset.ipynb
â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â”œâ”€â”€ preprocessing_pipeline.ipynb
â”‚   â”œâ”€â”€ augmentations.py
â”‚   â”œâ”€â”€ dataset_pipeline.py
â”‚   â””â”€â”€ preprocessing_config.json
â”œâ”€â”€ docs/                           # Reports, confusion matrix, accuracy graphs
â”œâ”€â”€ notebooks/                      # EDA & experiments
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
---
ğŸ‘¥ Team Members & Roles
Name               GitHub Username        Main Responsibility
Doha Mohamed       Doha-Mohamed2005       "GUI Development, Grad-CAM, Repo Owner"
Zeinab Mahmoud     0xZeinab               "GUI Assistance & Grad-CAM Integration"
Ahmed Ashraf       ahmedashrafmedo        "Training, Testing, Evaluation"
Abanoub Shenouda   Abanoub Shenouda       "Training, Testing, Evaluation"
Farid Elsharkawi   FaridElsharkawi        "Data Collection & Heavy Augmentations"
---
ğŸ›  Dataset Preprocessing
1ï¸âƒ£ Data Upload & Exploration

Downloaded Kaggle dataset and extracted

Analyzed class distribution and visualized (e.g., bar plot)

Reviewed sample images for quality and balance

2ï¸âƒ£ Image Preprocessing

Resize to 224x224

Normalize pixel values to [0,1]

Label extraction from filenames

3ï¸âƒ£ Data Augmentation

Geometric: Random flips, rotations, crops

Color: Hue and saturation adjustments

Lighting Robustness (BONUS): Brightness/contrast, shadows, glare

4ï¸âƒ£ Dataset Split

Train: 70%, Validation: 15%, Test: 15%

Stratified splitting to preserve class balance

5ï¸âƒ£ Saved Configuration

preprocessing_config.json includes:

Image size

Class mapping

Batch size

Augmentation settings
---
âš¡ Challenges & Learnings

Handling imbalanced lighting conditions required custom data collection and augmentations

Integrating Grad-CAM improved model interpretability

Collaborative GitHub usage ensured smooth teamwork
---
ğŸ“ Final Deliverables

Code repository (GitHub) with dataset links, models, and GUI code

Trained models and evaluation metrics

Functional GUI application (web-based via Streamlit)

Final report detailing dataset selection, model comparison, results, and challenges

Bonus demonstration of lighting robustness

